\chapter[sr]{Roman Pot simulation and reconstruction software}

\fig{fig/pdf/sr_sw_structure.pdf}{sr sw structure}{The structure of the \abb{RP} simulation and reconstruction software. Rectangles are used for software modules (algorithm implementations), bevels for data types.}

A good understanding of the processes that scattered protons undergo until they are detected by the \abb{RP} detectors is essential for the development and tuning of reconstruction techniques (techniques where the scattered proton kinematics is deduced from the \abb{RP} measurements). For this purpose computer Monte Carlo (\abb{MC}) simulation provides a very valuable tool. Consequently, the simulation and reconstruction modules form a significant part of the \abb{TOTEM} \abb{RP} software, the structure of which is sketched in \Fg{sr sw structure}. Besides the simulation and reconstruction blocks, you can see three more: alignment (special reconstruction and analysis focused on the alignment of \abb{RP} detectors), raw-data (experimental data preprocessing) and trigger (trigger-related analyses).

The contributions by this thesis' author mostly complement the work described in \bref{hubert}. We will focus on these contributions, but let us first briefly describe the software components (modules) from \Fg{sr sw structure}.

\> {\bf Event generator}.
The simulation process starts with generation of particles at the interaction point. This can be either a \em{particle gun} or a \em{physics event generator}. Particle guns generate particles according to some given distributions and are useful for specialized tests and software debugging. Physics event generators build events according to physics models. We use general-purpose physics generators like Pythia \bref{pythia6,pythia8} or Phojet \bref{phojet} and the custom developed Elegent (see \Sc{elegent}).

\> The aim of the {\bf beam smearing} module (see \Sc{beam smearing}) is to account for the beam smearing effects that are usually not considered by event generators. These smearing effects can be divided into three classes: \em{angular smearing} (the particles within a bunch are not all parallel), \em{energy smearing} (there is an energy fluctuation within a bunch) and \em{vertex smearing} (the bunches have non-zero dimensions, thus the interactions are distributed in space). 

\> The {\bf Geant4 and proton transport} module performs two actions: simulates the energy deposition in sensitive volumes and propagates protons in between. The sensitive volumes are located around the \abb{IP}5 (\abb{CMS}, \abb{T1} and \abb{T2}) and at the \abb{RP} stations. Both actions are implemented within the Geant4 \bref{geant4} simulation kit. For the proton transfer through the \abb{LHC} a polynomial parameterization model is used (see Ch.~6 in \bref{hubert}). For details on the implementation we refer the reader to Sec.~7.3 in \bref{hubert}.

\> The energy deposited in the silicon sensors gives rise to electron-hole pairs, which are collected by the strips and the resulting electric signal is processed by the \abb{VFAT} chips \bref{vfat}. A simulation of these processes takes place in the {\bf sensor response and electronics simulation} modules, details can be found in Sec.~7.4 in \bref{hubert}.

\> The \abb{VFAT}s are digital chips, their output is a boolean value (hit/no hit) per sensor channel. A collection of \abb{VFAT} data is called the {\bf \abb{DIGI}} data type. This is the meeting point of the simulation and raw-data chains and is the start point for reconstructions and analyses.

\> The {\bf raw data} type refers to a data format in which detector data are collected and saved by the data acquisition (\abb{DAQ}) system.

\> The \abb{DAQ} system has only a limited possibility to perform consistency checks at run-time. Therefore it is essential to perform a {\bf raw-data validation} when converting the raw-data to \abb{DIGI} offline. This validation relies on checking various frame check sums, constant bits and comparing chip IDs, event and bunch-crossing numbers to the expected values.

\> The {\bf fast simulation} modules (see \Sc{fast simu}) provide a less detailed, but faster alternative to the Geant4-based simulation. They are primarily intended for statistical studies of the track-based alignment.

\> The {\bf clusterization} is the first step of the reconstruction chain. Due to charge-sharing effects, it is possible that one track fires two or more neighbouring strips. Such strip clusters need be identified and later treated as a single hit.

\> The position of a cluster can be expressed as the distance (in the read-out direction, see \Fg{rp station 3d}) from the center of the sensor. A collection of such cluster positions is called the {\bf \abb{RECO}} data type.

\> The aim of the {\bf pattern recognition} is to match sensor hits with particle tracks. This implicitly includes suppressing noise hits that are not associated with any track. There are two pattern recognition algorithms in the \abb{TOTEM} software. Both of them search for linear patterns within the (\abb{RECO}) hits in each \abb{RP}. The algorithm described in \Sc{pattern reco} can be used with tracks with arbitrary angles (advantageous for track-based alignment applications), the algorithm presented in Sec.~8.1.4 in \bref{hubert} is designed for the protons coming from the \abb{IP} -- such protons are almost parallel to the beam.

\> During {\bf one-\abb{RP} track fitting}, the hits from $U$ and $V$ sensors of each \abb{RP} are combined into one $xyz$ (global reference frame) fit, see Sec.~8.1.5 in \bref{hubert}.

\> The purpose of {\bf station track fitting} is similar to the one-\abb{RP} track fitting, but here all hits from a station are combined. This module has been developed mainly for alignment purposes. For a good noise suppression efficiency, this algorithm comprises also an outlier removal procedure. It will be discussed in \Sc{al data sel}.

\> In the {\bf physics reconstruction} step, the one-\abb{RP} track fits are used to reconstruct proton(s) kinematics at the interaction point and consequently determine the type and kinematic parameters of the event. There are two versions -- one suitable for any diffractive protons and a lighter alternative for elastic events. The latter one will be discussed in \Sc{elr}.

\> The {\bf alignment} modules implement the \abb{RP} alignment methods presented in \Sc{al}.
%There is no standardized module for the elastic alignment (\Sc{al elast}) yet, so far it has been performed together with elastic scattering analyses.

\> The \abb{DIGI} data contain also some trigger-related information, which can be used for validations of the trigger system performance -- these are drawn as the {\bf trigger analysis} module.

\> The {\bf data quality monitor} (Totem\abb{DQM}) is an interactive program that can visualize the results of all the steps shown in \Fg{sr sw structure}. It has primarily been designed for (quasi)-online control of the data being acquired. But it has also proved useful for event scanning (visual inspection of the events' details) or for software tuning and debugging. The Totem\abb{DQM} \bref{totemdqm} provides a multi-window/tab user interface, each of the windows contains a configurable grid of plots, see an example in \Fg{dqm ex}. The plots can be either \em{cumulative} (built from the entire event sample) of \em{event-related} (showing details of a chosen event). Cumulative plots are for example $U$ and $V$ hit profiles (bottom-right window in \Fg{dqm ex}) or $xy$ hit maps (top-right window). Several event-related plots are shown in the background window (left-hand side): track fits in $U$ and $V$ projections and a $3D$ view of the fitted track within the detector package.

\fig[10cm]{fig/external/dqm.png}{dqm ex}{A screen shot of several Totem\abb{DQM} windows.}


\section[elegent]{Elegent}

Elegent is an acronym for ELastic Event GENeraTor. It generates elastic $\rm pp$ and $\rm\bar pp$ collisions with $\d\si/\d t$ distributions according to the four phenomenological models outlined in \Sc{el models}.

The package consists of two components. The first one prepares a set of cumulative distribution functions (\abb{CDF}s). This set is saved as a ROOT file and corresponds to a chosen energy $\sqrt s$ and interaction type $\rm pp$ or $\rm \bar pp$. For each of the six model variants from \Sc{el models}, four \abb{CDF}s are calculated: ignoring the Coulomb interaction and treating the Coulomb-hadronic interference according to the West-Yennie (\Eq{el phase WY}), simplified West-Yennie (\Eq{el phase SWY}) and (corrected) Kundr\' at-Lokaj\' i\v cek (\Eq{el phase CKL}) approaches.

The second package component loads a chosen \abb{CDF} and generates random elastic events (the inversion method is used, see e.g.~Sec.~2.2 in \bref{lemieux}), which are stored in the HepMC format \bref{hepmc}.

For technical details and usage instructions we refer the reader to the manual page \bref{elegent}.



\section[beam smearing]{Beam smearing}

Most physics event generators consider head-to-head collisions of particles of a fixed energy at a given space point. However, in reality there are two bunches collided under a certain crossing angle (see \Fg{smearing vertex}). Within each bunch, the particles do not have identical energies (energy smearing) and their momenta are not all parallel (angular smearing). The bunches have non-zero dimensions and therefore the interactions may take place at various space points (vertex smearing). In the following two subsections we will describe these effects in detail. This text is an updated version of the internal note \bref{smearing}.


\subsection{Angular and energy smearing}

Most event generators describe the collisions in a reference frame (\abb{MC} frame), where the incident particles approach each other along the $z$ axis, each with the nominal momentum $p_{\rm nom}$. However, a real collision in the \abb{LAB} frame (bound to the accelerator) looks different, see \Fg{smearing angular energy}. Because of the energy smearing each incident proton has slightly different momentum (the $\xi$ factors) and because of the crossing angle $\al$ and the angular smearing (the $C$ factors) they do not collide head on.

\fig[8cm]{fig/pdf/smearing_angular_energy.pdf}{smearing angular energy}{A collision seen in the $xz$ plane of the \abb{LAB} frame (bound to the accelerator). The momenta of the protons are altered due to the energy smearing (the $\xi$ factors), the directions are modified due to the crossing angle $\al$ and angular smearing (the angles $C$).}

Therefore a part of these smearing effects can be described by a Lorentz transformation from the \abb{MC} to the \abb{LAB} frame. But there is another part, reflecting the fact that the smearing alters the center-of-mass energy $\sqrt s$. Thus to simulate the smearing correctly, one should first generate the smearing parameters ($\xi$ and $C$) for every event, then calculate the center-of-mass energy $\sqrt{s_{\rm LAB}}$ and then ask the event generator to build an event for this energy $\sqrt{s_{\rm LAB}}$. However, this is technically difficult, most event generators generate events for a fixed energy $\sqrt{s_{\rm MC}}$. Since the energy smearing is a small effect (see \Eq{ttm energy fl}), we have decided to use an approximation -- each event is generated for a center-of-mass energy $\sqrt{s_{\rm MC}}$, but then the four-momenta of all particles involved are rescaled such that the center-of-mass energy becomes $\sqrt{s_{\rm LAB}}$. This means to scale the energy of each particle as
\eqref{E^{\rm MC} \rightarrow \chi\, E^{\rm MC},\qquad \chi = \sqrt{s_{\rm LAB}\over s_{\rm MC}}\ .}{sm energy scaling}
The momenta are scaled such that the masses are preserved. Later on, we will refer to this scaling procedure as $S(\ch)$.

Now let us come back to the Lorentz-transformation part of the smearing effects. This part transforms the event kinematics from \Fg{smearing angular energy} to the situation where the particles collide with equal momenta and along the $z$ axis. The transformation can be decomposed into a boost (making the momenta $\vec p_1$ and $\vec p_2$ have the same magnitude and opposite direction) and a rotation (making the momenta be parallel to the $z$ axis).

If we write the boost transformation of a four-momentum $(E|\vec p)$ to $(E'|\vec p')$ in the following form ($\vec\be$ denotes the relative velocity between the two reference frames)
\eqref{\eqalign{
E'      &= \ga\,(E - \vec p\cdot\vec\be)\cr
\vec p' &= \vec p  +  (\ga - 1) {\vec p \cdot \vec \be\over \be^2}\vec\be - \ga E \vec\be\cr
}\qquad\eqalign{
\be &= |\vec\be|\cr
\ga &= {1\over\sqrt{1 - \be^2}}\cr}
\ ,}{sm lorentz}
one can find that the $\vec\be$ needed for our purpose is
\eqref{\vec\be = {\vec p_1 + \vec p_2\over E_1 + E_2}\ ,}{sm beta}
where $\vec p_1, \vec p_2$ are the momenta and $E_1, E_2$ are the energies of the incident particles in the \abb{LAB} frame (as shown in \Fg{smearing angular energy}). Let us denote this transformation $L(\vec\be)$ and the boosted momenta of the incident particles $\vec p_1'$ and $\vec p_2'$.

Using the Rodrigues' formula to describe the rotation of a vector $\vec v$ by an angle $\om$ around a unit vector (axis) $\vec a$:
\eqref{R(a, \om)\, \vec v = \vec v\,\cos\om + \vec a\times\vec v\,\sin\om + \vec a\cdot\vec v\,\vec a\,(1 - \cos\om)\ ,}{sm rotation}
one can find a rotation that makes the boosted momenta $\vec p_{1, 2}'$ parallel to the $z$ axis:
\eqref{\vec a = {\vec p_1' \times \hat z\over |\vec p_1' \times \hat z|}, \qquad \cos\om = {\vec p_1' \cdot \hat z\over |\vec p_1'|}}{sm axis angle}
where $\hat z = (0, 0, 1)$ is the unit vector in the $z$ direction in the frame after the boost.

To summarize, if $(E|\vec p)_{\rm MC}$ is the four-momentum of a particle produced in a \abb{MC} event, then the smeared \abb{LAB} four-momentum of that particle can be written as
\eqref{(E|\vec p)_{\rm LAB} = L(-\vec\be)\ R(\vec a, -\om)\ S(\chi)\ (E|\vec p)_{\rm MC}\ .}{sm mc to lab}


The above formula provides a method to apply the angular and energy smearing to events from \abb{MC} generators. What is still missing is a specification of the $\vec\be$, $\vec a$, $\om$ and $\ch$ distributions. But these can be calculated from the beam-smearing parameters introduced in \Sc{rp measurement}. Considering a crossing angle $\al$, see \Fg{smearing angular energy}, one can parameterize the momenta of the incident particles as
\eqref{\vec p_i = \pm p_{\rm nom}\,(1 + \xi_i)\,\pmatrix{\cos\al & 0 & \mp \sin\al\cr 0 & 1 & 0 \cr \pm\sin\al & 0 & \cos\al\cr}\,\pmatrix{C_i\cr S_i\cr \sqrt{1 - C_i^2 - S_i^2}}\ ,}{sm momenta par}
where $i = 1, 2$ and the upper (bottom) sign corresponds to particle 1 (2). The $C_i$ and $S_i$ parameters describe the angular smearing in the horizontal ($x$) and vertical ($y$) projections. In a good approximation, these parameters are normally distributed with a spread $\si_{\th^*}$ defined in \Eq{ttm beam div}. To be precise, the tails of the distribution must be cut off since the parameterization requires $S_{1,2}^2 + C_{1,2}^2 \leq 1$. But as any realistic $\si_{\th^*} \ll 1$, the effect is negligible. The $\xi$ parameter accounts for the energy smearing, the expected distribution is a Gaussian with mean $\bar\xi$ and variance $\si_\xi^2$, see \Eq{ttm energy off,ttm energy fl}.

The smearing software module uses the above distributions and the parameterization \Eq{sm momenta par} to generate the smearing parameters and \Eq{sm mc to lab} to apply the smearing to \abb{MC} generated events.

The smearing effects and the crossing angle are rather small: $\si_{\th^*} \sim \O{10^{-6}\un{rad}}$, $\al \sim \O{10^{-4}}$ and $\si_\xi \sim \O{10^{-4}}$, see \Sc{rp measurement}. Therefore, one may simplify \Eq{sm mc to lab} by keeping just the first order terms. It will yield a formula with an instructive interpretation which will become useful for reconstruction-uncertainty estimates. Also, bearing in mind the \abb{LHC} energies, we will approximate $E\approx p$ for all the particles involved. In this approximation \Eq{sm beta} gives
\eqref{\vec\be \simeq {1\over 2}\pmatrix{-2\al + C_1 - C_2\cr S_1 - S_2\cr \xi_1 - \xi_2}}{sm beta expl}
and thus $\ga\simeq 1$ (all other terms are of second and higher orders). Then, the boost \Eq{sm lorentz}, rotation \Eq{sm rotation} and scaling factor \Eq{sm energy scaling} simplify to
\eqref{\vec p' \simeq \vec p - |\vec p| \vec\be,\qquad E' \simeq E - \vec p\cdot\vec\be\ ,}{sm lorentz expl}
\eqref{R(\vec a, \om)\,\vec v \simeq \vec v + {1\over 2}\pmatrix{S_1 + S_2\cr -C_1 - C_2\cr 0} \times \vec v\ ,}{sm rotation expl}
\eqref{\ch \simeq 1 + {\xi_1 + \xi_2\over 2}\ .}{sm energy scaling expl}
Now we are ready to apply \Eq{sm mc to lab} to an outgoing (\abb{MC} generated) particle with momentum $\vec p_{\rm MC}$. Let us limit ourselves to particles that can reach the \abb{RP} stations, that means particles scattered to small angles $\th \ls 10^{-3}\un{rad}$. A convenient parameterization, thus, is
\eqref{\vec p_{\rm MC} = \pm p\,\pmatrix{\th\cos\ph\cr \th\sin\ph\cr 1\cr} \.}{sm diff mc}
The particles with $+$ ($-$) sign can be detected in the right (left) arm \abb{RP} stations. Still working in the leading approximation, one finds
\eqref{\vec p_{\rm LAB} = \pm p\,\pmatrix{\th\cos\ph + \De\th_x\cr \th\sin\ph + \De\th_y\cr 1 + \xi\cr},
\quad \xi = \left\{\matrix{\xi_1\cr\cr \xi_2}\right.,
\quad \De\th_x = \left\{\matrix{C_1 - \al\cr\cr C_2 + \al\cr}\right.,
\quad \De\th_y = \left\{\matrix{S_1\qquad\hbox{for right arm}\cr\cr S_2\qquad\hbox{ for left arm}\cr}\right.\ .}{sm diff lab} %}}}
The interpretation is quite intuitive. Let us take, for instance, a proton heading for the right arm and let us focus on the horizontal ($x$) projection. Its full scattering angle is a sum of three components: the original (\abb{MC}) scattering angle ($\th\cos\ph$), crossing angle ($-\al$) and the $x$ component of the beam divergence ($C_1$). The proton inherits the relative-momentum shift $\xi_1$ from the first incident proton.


\subsection{Vertex smearing}

\fig[8cm]{fig/pdf/smearing_vertex.pdf}{smearing vertex}{A bunch collision under a crossing angle $\al$, described in the \abb{LAB} frame.}

Let us imagine a collision of two bunches as shown in \Fg{smearing vertex}. Each of them is propagating with a speed $v$ in the \abb{LAB} frame, they collide under a crossing angle $\al$. The particle densities of the bunches at a time $t$ can be described by functions $\rh_{1, 2}(x, y, z; t)$. Then, from Sec.~4.5 in \bref{peskin} (in particular Eq.~(4.60)) one can conclude that the probability of finding an interaction (vertex) at a position $(x, y, z)$ and time $t$ is proportional to the product of the two densities:
\eqref{h(x, y, z; t) \propto \rh_1(x, y, z; t)\, \rh_2(x, y, z; t)\ .}{sm pdf2}

In a good approximation one may assume that each of the bunch densities is time-independent when described in the rest frame of the bunch. Denoting this rest-frame density $\rh_0(\tilde x, \tilde y, \tilde z)$ (tildes are used for the rest-frame coordinates, see \Fg{smearing vertex}), one may write for the second bunch:
\eqref{\rh_2(x, y, z; t) = \ga\, \rh_0\Big(x\cos\al - z\sin\al, y, \ga(z\cos\al + x\sin\al + vt) \Big)\ ,}{sm density2}
which follows from the Lorentz transformation (the origins of the \abb{LAB} and rest frames coincide at $t=0$):
\eqref{
	\tilde x = x\cos\al\ - z\sin\al\ ,\qquad
	\tilde y = y\ ,\qquad
	\tilde z = \ga \left( z\cos\al\ + x\sin\al + vt \right)\ ,\qquad
	\ga = {1\over\sqrt{1 - v^2}}\ .
}{sm coord trans}
The leading $\ga$ factor on the \rhs~of \Eq{sm density2} is needed to preserve the normalization:
\eqref{\int \rh_0(\tilde x, \tilde y, \tilde z)\ \d\tilde x\,\d\tilde y\,\d\tilde z = \int \rh_2(x, y, z)\ \d x\,\d y\,\d z\ .}{sm rho normalization}
The density for the first bunch can be obtained analogically:
\eqref{\rh_1(x, y, z; t) = \ga\, \rh_0\Big(x\cos\al + z\sin\al, y, \ga(z\cos\al - x\sin\al - vt) \Big)\ .}{sm density1}

The Lorentz-contracted particle density of each bunch can be, in a first approximation (see \bref{white10}), described by a Gaussian:
\eqref{\ga \rh_0(x, y, \ga z) \propto \exp\left(-{ x^2\over 2\si_{x^*}^2}-{ y^2\over 2\si_{y^*}^2}-{ z^2\over 2\si_{z^*}^2}\right),}{sm density}
where the spreads $\si_{x^*}, \si_{y^*}$ and $\si_{z^*}$ correspond to the bunch dimensions in the \abb{LAB} frame (cf.~\Eq{ttm vertex sm}).

By now we have collected all the ingredients to evaluate the vertex distribution $h$ from \Eq{sm pdf2}. Moreover, since we are not interested in the time of collisions, we may integrate over the time $t$ and obtain the spatial distribution of vertices:
\eqref{h(x, y, z) \propto \exp\left[- {\cos^2\al\over\si_{x^*}^2} x^2 - {y^2\over\si_{y^*}^2} - \left({\sin^2\al\over\si_{x^*}^2} + {\cos^2\al\over\si_{z^*}^2}\right)z^2\right]\.}{sm vertex distribution}
This distribution has a Gaussian form with spreads
\eqref{
	\si_{x} = {\si_{x^*}\over\sqrt{2}\cos\al},\quad
	\si_{y} = {\si_{y^*}\over\sqrt{2}},\quad
	\si_{z} = {\si_{z^*}\over\sqrt{2}}\,{\si_{x^*}\over\sqrt{\si_{z^*}^2\sin^2\al + \si_{x^*}^2\cos^2\al}} \.}{sm effective variations}
This formula is used by the software module. For each event a random vertex is generated according to this distribution and the interaction (of the event) is placed to this vertex.


\section[fast simu]{Fast simulation}

In order to test the performance of the track-based alignment (see \Sc{al tb}), we have made a large number of \abb{MC} simulations. With a Geant4-based approach it would have taken an enormous amount of computer resources. Instead, we have developed two fast simulation modules (see \Fg{sr sw structure}): \em{fast simulation} and \em{fast (one-)station simulation}. The first one takes a smeared event as an input and transports the forward protons to the \abb{RP} stations using the polynomial optics approximation (the same as used for reconstruction). This module thus performs a fast simulation of physics events. However, background tracks (such as beam halo or products from beam-gas interactions) can be used for alignment too. For these tracks one can expect wider angular distribution which is advantageous for alignment purposes, see e.g.~\Fg{al err rotz theta}. To study the influence of the track distribution on the alignment performance, we have developed the other fast simulation module -- the one-station simulation. This module generates random tracks (according to a given distribution) at the entrance of a chosen station.

Further proton track processing is in common for both modules. Within a station, the tracks are interpolated linearly and the intersections with all sensors are calculated. If the \pmt{roundToPitch} parameter is set to true, then the hit position is rounded to the nearest strip or inter-strip position. The mechanism is illustrated in \Fg{sr fast simulation scheme}. If the intersection falls in one of the blue regions, the creation of a double-strip cluster is assumed and the hit position is rounded to the inter-strip position (dash-dotted line). Otherwise one-strip clusters are assumed and the position is rounded to the nearest strip. The strip pitch $P$ can be set by the \pmt{pitch} parameter, the size of the double-strip-cluster region (blue) by the \pmt{dscrWidth} parameter. Each hit is assigned an uncertainty of $\si_{\rm P} = P/\sqrt{12}$.
% unless the \pmt{dscReduceUncertainty} parameter is set to true. In that case, the uncertainty of double-strip hits is reduced to a half: $P/\sqrt{48}$.

\fig{fig/pdf/sr_fast_simulation_scheme.pdf}{sr fast simulation scheme}{One and two-strip cluster regions as used in the fast simulation. The solid lines represent the strip centers, the dash-dotted lines mark the half way between the strips. The blue areas correspond to the double-strip-cluster regions, the white ones to the regions where one-strip clusters are created.}


\section[pattern reco]{Pattern recognition}

The aim of this module is to associate sensor hits with particle tracks. The input is a list of \abb{RECO} hits among which track patterns shall be searched. The search is done pot per pot. Within each pot, protons follow straight lines, which defines the pattern to be searched.

The fact that there are just two read-out directions ($U$ and $V$) makes the task special. The line-pattern search in $UVz$ space (see \Fg{rp station 3d}) can be decomposed into searches in the $Uz$ and $Vz$ projections. However, this also means that there is no hint how to combine the recognized patterns from the two projections. Consequently, only events with one track per pot (only one combination of $Uz$ and $Vz$ line patterns) can be fully reconstructed. For example, imagine two tracks in a pot. Then, two line patterns would be found in each projection, yielding four possible $UVz$ combinations. However, two of them correspond to the real tracks and the other two are fake combinations (ghosts). Even if we consider the rotation misalignment (see \Tb{al exp misal}), the deviations from the $U$ and $V$ read-out directions are insufficient to remove this ambiguity. 

Our algorithm is an optimization of the Hough transformation pattern search (see e.g.~Sec.~2.4.3.4.~in \bref{bock}). Let us parameterize the line patterns by a slope $a$ and an intercept $b$ ($q$ stands for either $u$ or $v$):
\eqref{q = a (z - z_0) + b\ .}{pr line par}
Here, $z_0$ refers to the center of the \abb{RP}. This is an advantageous choice since it is the ''nearest'' point to all the planes, therefore it minimizes the impact of the slope $a$ determination error on the intercept $b$ determination. The Hough transformation assigns to each point $(z, q)$ a line in the $ab$ space:
\eqref{(z, q)\qquad \longrightarrow\qquad b = - (z - z_0) a + q \ .}{pr transform}
This process is shown in \Fg{sr pattern reco}: each of the points in the left plot is transformed into a line (of the same color) in the right plot. The effect is evident -- the intersections of colored lines (corresponding to the colored points that lie around a line) cumulate together, but the intersections of the black line (representing a noise hit) are scattered around. Hence the task of finding line patterns is reduced to an (intersection) cluster search.

Since the hit positions are multiples of the pitch $P$, it is natural to measure the intercept $b$ in the units of $P$. Similarly, we will give the slopes $a$ in multiples of $a_0 \equiv P / d$, where $d = 9 \un{mm}$ is the nominal distance between two adjacent planes of the same strip orientation (see \Sc{ttm det}).

\fig{fig/pdf/sr_pattern_reco.pdf}{sr pattern reco}{An illustration of the pattern recognition method. Left: side-view on the five sensors (black vertical lines) of identical strip orientation ($U$ or $V$). The horizontal ticks represent the strip positions. The thick inclined line shows a track, the colored points around mark the measurements by the five sensors. The black dot in the upper-left corner represents a noise hit. Right: the corresponding Hough diagram. The colors of the lines correspond to the colors of the points in the left plot. The line intersections are marked with black dots. The gray region represents a cluster (of the optimal size -- see \Tb{pattern reco par}).}

Now, let us describe the cluster-search algorithm. Each hit is assigned a weight $w = \si_0/\si$, where $\si$ the uncertainty of the hit and $\si_0 = 66/\sqrt{12} \un{\mu m}$ is the uncertainty of a 1-strip cluster. The weight of a line crossing is given by the sum of the two contributing hit weights. Then, the algorithm can be described as follows.

\bitm
\itm Build clusters: go through all crossings, try to match each crossing with any of the already existing clusters. A crossing matches with a cluster if
\eqref{|a - a_c| < \pmt{clusterSize\_a}/2 \quad \hbox{ and }\quad |b - b_c| < \pmt{clusterSize\_b}/2\ ,}{pr cluster match}
where $a$ and $b$ are the coordinates of the crossing and $a_c$ and $b_c$ give the position of the cluster. The cluster position is calculated as a weighted mean over all contributing crossings, for example: $a_c = \sum a_i w_i / \sum w_i$. If the line crossing matches with a cluster, it is added to that cluster. If the line crossing does not match with any cluster, a new cluster is created, containing this crossing only.
\itm For each cluster a weight is calculated as the sum of the weights of the hits involved in the cluster.
\itm Take the cluster with the highest weight. If its weight is lower than the \pmt{threshold} parameter, stop. If it is higher, the cluster corresponds to a recognized track. Hits corresponding to that cluster are removed from the list and one returns to the step 1 to recognize more line patterns.
\eitm

\vskip\itskip
The \pmt{threshold} parameter gives an effective minimal number of hits for a cluster to be trusted as a reasonable line. The other two important parameters are the cluster sizes. If set too low, real tracks would not be recognized, if set too high, noise hits may get selected too or even multiple tracks may be merged. The needed cluster size depends on the expected deviations of the individual measurements from the track. These deviations have two major ingredients: the pitch size and misalignments. To find the optimal cluster sizes we have made a simple \abb{MC} test and a real data analysis, see \Fg{sr pattern reco tune}. For the \abb{MC} test, we have simulated  1000 (internal) misalignment scenarios compatible with \Tb{al exp misal}%
%(slope $50\un{\mu m}$ per detector, deviations with the variation of $20\un{\mu m}$)
. For each misalignment, we have simulated 1000 tracks through 5 planes separated by the nominal distance $d$, the angular spread of tracks has been $\si_\th = 5\un{mrad}$. For each track we have calculated the cluster size and filled the values in the blue histograms. The red histograms correspond to an analysis of \abb{LHC} physics data (run 3728). For both projections we have required each of the five planes to contain exactly one hit -- a perfect track. Looking at \Fg{sr pattern reco tune}, one can see non-negligible differences between the two histograms at lower cluster-size values (the \abb{MC} has been too simple), but both agree that there are practically no events above $3a_0$ and $4P$. Therefore we have decided to use these values as the optimal cluster sizes.

\fig{fig/pdf/sr_pattern_reco_tune.pdf}{sr pattern reco tune}{Cluster-size distributions: \abb{MC} simulation (blue) and run 3728 (red).}

In order to optimize the performance of the software module, we skip the events with fewer reasonable planes per projection than \pmt{minPlanesPerProjectionToSearch}. By reasonable planes we mean those, where the number of hits is non-zero but smaller than \pmt{maxHitsPerPlaneToSearch}. We recall that only events with one track can be fully reconstructed.

\Tb{pattern reco par} summarizes the parameters of the algorithm and gives their default/optimal values. \Fg{sr pattern reco ex} provides an example of the recognition results.

\tab[\strut\quad\pmt{#}\hfil&\quad\hfil$#$\hfil\quad\cr]{pattern reco par}{The parameters of the pattern recognition algorithm with their default values.}{\ln
clusterSize\_a& 3a_0\cr
clusterSize\_b& 4P\cr
maxHitsPerPlaneToSearch& 4\cr
minPlanesPerProjectionToSearch& 3\cr
threshold& 3\cr\ln
}

\fig{fig/pdf/sr_pattern_reco_ex.pdf}{sr pattern reco ex}{An example of the pattern recognition (run 3230, file 0, event 111, 45-220-near unit). Left: a track plus noise in the bottom pot ($V$ sensors). Right: many tracks in the horizontal pot ($V$ sensors). The red lines correspond to the recognized patterns.}

\eject %!
\section[elr]{Reconstruction of elastic events}

In the note \bref{el reco} we described a module performing a reconstruction of elastic events. It is a light-weight alternative to the inelastic proton reconstruction (see Sec.~8.2 in \bref{hubert}). The primary aim of this study (performed during the simulation phase of the experiment) was to quantify the capabilities of the \abb{RP} system with various optics. In this section, we will present an update to that note. One of the main differences is the use of a more accurate beam smearing description (as presented in \Sc{beam smearing}). Compared to the old study, the beam divergence has effectively increased by a factor of $\sqrt 2$ (cf.~Eq.~(17) in \bref{smearing}). We will constrain ourselves to the most interesting results, for the others we refer the reader to the original note \bref{el reco}.
%We will skip the studies of the hypothetical situations without beam smearing. We will also skip the discussion of the peak structures appearing in certain histograms. These only occur with perfectly aligned detectors, therefore they correspond to a hypothetical situation too.

The elastic reconstruction (a type of physics reconstruction, see \Fg{sr sw structure}) follows after the one-\abb{RP}-track fitting. In the note \bref{el reco} we showed that the lever-arm of single \abb{RP} is too short for a reasonable angular reconstruction. That is why we take only the hit position from the one-\abb{RP}-track fits.

Elastic protons have by definition no momentum loss, that is $\xi \equiv 0$. For such protons, the transport equation \Eq{ttm lin par} simplifies to:
\eqref{x(s) = L_x(s)\, \th_x^* + v_x(s)\, x^*\ ,\qquad y(s) = L_y(s)\, \th_y^* + v_y(s)\, y^*\ .}{elr track param}
We have written the optical functions as functions of the distance $s$ from \abb{IP} only, since in a very good approximation they do not depended on the proton's scattering parameters $x^*$, $y^*$, $\th^*_x$ and $\th^*_y$ (see e.g.~\bref{avati05}).

The hit positions $x$ and $y$ are known from the one-\abb{RP}-track fits. Assuming that we know the optical functions corresponding to all \abb{RP}s involved in the event, we may use the least squares (\abb{LS}) estimation to obtain the scattering parameters (see e.g.~Sec.~6.6 in \bref{barlow}):
\eqref{\pmatrix{x^*\cr\th_x^*} = {1\over \sum v^2 \sum L^2 - \sum vL \sum vL} \pmatrix{\sum L^2 \sum x v - \sum vL \sum x L\cr -\sum vL \sum x v + \sum v^2 \sum x L}\ ,}{elr fit}
where for example $\sum x L$ abbreviates $\sum_{i} x(s_i) L_x(s_i) / \si_x^2(s_i)$ with $\si_x$ representing the uncertainty of the $x$ measurement (one-\abb{RP}-track fit) and $i$ enumerating the \abb{RP} fits. A similar equation can be written for the $y$ projection. In fact, since the proton transport \Eq{elr track param} does not mix $x$ and $y$ projections, they decouple in the fit and one can perform $x$ and $y$ fits separately. The treatment is equal for both projections, thus we will write all formulae for the $x$ projection only in what follows.

The \abb{LS} estimator gives also the covariance matrix for the fit parameters (see e.g.~Eq.~(6.24) in \bref{barlow}):
\eqref{\mathop{\rm Var}[x^*, \th^*] = {1\over \sum v^2 \sum L^2 - \sum vL \sum vL} \pmatrix{\sum L^2 & - \sum vL \cr -\sum vL & \sum v^2 }\ .
}{elr fit err}

The module includes a simple \em{hit selection} (to suppress noise etc.) and an \em{event selection} (to distinguish elastic events from other processes like \abb{DPE}). The algorithm can be described by the three steps below.

\bitm
\itm \em{Hit selection}. The aim is to suppress hits (one-\abb{RP} track fits) that do not belong to the elastic event. The implementation is based on the fact that the $L\th^*$ terms dominate in the proton transport \Eq{elr track param}
%(\TODO{more justification})
. When a $x/L_x$ histogram is build, the hits of an elastic event tend to cluster together, as illustrated in \Fg{elr road search}. The typical cluster-size is optics-dependent and thus is a parameter of the algorithm, called \pmt{road-size}.

\fig{fig/pdf/elr_road_search.pdf}{elr road search}{An illustration of the hit selection. Left: sample \abb{RP} hits shown vs\hbox{.} the corresponding effective length. The hits by elastic protons are drawn in blue, background/noise in red. Right: the corresponding histogram of ratios $x/L_x$.}

\itm \em{Fitting}. There are three fits performed according to \Eq{elr fit}: left-arm, right-arm and global fit. The left-arm fit is carried out through hits from the left-arm only, analogously for the right-arm fit. The global fit uses all hits available.

\itm \em{Elastic event selection}. Here, the left and right-arm fits are compared. For an ideal elastic scattering event, the left and right scattering angles are identical and, indeed, there is just one vertex. Thus, the left and right fit results ($\th_x^*$ and $x^*$) should coincide. Practically we set \pmt{tolerance}s for the left-right differences of the scattering angles and vertex coordinates.
\eitm

\vskip\itskip
In total, there are three parameters per projection (\pmt{road-size}, \pmt{angular tolerance} and \pmt{vertex tolerance}). For most optics
%\TODO{ref}
, the dominant smearing effect is the beam divergence. Therefore the \pmt{angular tolerance} should be set to few times the standard deviation of the beam divergence (see e.g.~\Sc{rp measurement}). Similar argument applies to the \pmt{road-size} parameter. There one should also account for neglecting the $v$ terms in the proton transport \Eq{elr track param}. Thus reasonable values will be larger than those for \pmt{angular tolerance}. In fact, the best way to determine reasonable settings is to run a \abb{MC} with elastic events only, do the reconstruction with no cuts and look at the distributions of the cut parameters. This will be done later on in \Sc{elr 1535,elr 90}.

But before turning to optics-dependent results, let us discuss what measurement uncertainties we expect for the quantities of interest -- most notably the scattering angle $\th^*$ and the momentum-transfer $t$. The measurement (fit) uncertainties can be determined from the covariance matrix \Eq{elr fit err}. Moreover, typical \abb{TOTEM} optics
%\TODO{ref}
have properties that will allow us to derive a much simpler formula. First, the effect of the $v$ terms in the proton transport \Eq{elr track param} can often be neglected to the effect of the $L$ terms (with the exception of the horizontal projection at the $\be^*=90\un{m}$ optics, which we will discuss later). Second, let us constrain ourselves to the situation where only the $220\un{m}$ stations are used (typical until the end of 2010). The variation of the effective lengths $L_x(s)$ within a station is not large, thus we might think of a ``typical effective length'' $L_x$. Under these simplifications, the scattering angle estimator becomes:
\eqref{\th_x^*
	\quad\mathop{\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\longrightarrow}\limits^{v \hbox{\SmallerFonts\ neglected}}\quad
		{\sum L x\over \sum L^2}
	\quad\mathop{\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\longrightarrow}\limits^{\hbox{\SmallerFonts\ typical }L}\quad
	{\sum_{\rm R} x - \sum_{\rm L} x\over (N_{\rm R} + N_{\rm L}) L_x}
\ ,}{elr th fit sim} 
where for example $\sum_{\rm R}$ represents the sum over the right-arm hits only and $N_{\rm R}$ is the number of the right-arm hits. In this model, the error contributions to a measurement can be written as
\eqref{x = L_x (\th_x^* + \De\th_x) + \De x\ .}{elr x meas}
$\th_x^*$ represents the true scattering angle, $\De\th_x$ its alternation due to the beam smearing, see \Eq{sm diff lab}, which is independent for left and right arms. The error $\De x$ combines two effects -- misalignment and the error due the finite resolution of the silicon detectors. The misalignment leads to a systematic shift and we will not discuss it here (see e.g.~\Tb{al reco impact}). Had we only one sensor per \abb{RP} (per projection), the finite-resolution error could be well described by an uniform distribution between plus and minus half of the strip pitch $P$, which would give a standard deviation $\si_{\rm P} = P/\sqrt{12}\approx 19\un{\mu m}$. In reality, there are five sensors per projection in each \abb{RP}, thus one might naively expect the standard deviation to reduce by a factor $\sqrt 5$. But since physics tracks are almost perpendicular to the sensors, they most often hit the same strip in all five sensors and thus the reduction is not justified. Because of small misalignments of the sensors within a stack, the distribution of $\De x$ is rather Gaussian-like, but the standard deviation $\si_{\rm P}$ is retained (see Fig.~4.19 in \bref{totem08}).

Inserting \Eq{elr x meas} to the rhs.~of \Eq{elr th fit sim} yields an estimate for the reconstruction error (reconstructed value minus the original one)
\eqref{\De\th_x^* = \De_{\rm B}\th_x^* + \De_{\rm R}\th_x^*\ ,
	\quad \De_{\rm B}\th_x^* = {N_{\rm R} \De\th_x^{\rm R} - N_{\rm L} \De\th_x^{\rm L}\over N_{\rm R} + N_{\rm L}}\ ,
	\quad \De_{\rm R}\th_x^* = {1\over L_x} {\sum_{\rm R} \De x - \sum_{\rm L} \De x\over  N_{\rm R} + N_{\rm L}}\ ,
}{elr th err proj}
where we have introduced the error components due to the beam divergence $\De_{\rm B}\th_x^*$ and due to the finite resolution $\De_{\rm R}\th_x^*$. To a good approximation, both components have zero mean value and their standard deviations can be estimated to
\eqref{
	\si_{\rm B} = {\sqrt{N_{\rm R}^2 + N_{\rm L}^2} \over N_{\rm R} + N_{\rm L}}\, \si_{\th^*}\ ,\qquad
	\si_{\rm R} = {1\over L_x} {1\over \sqrt{N_{\rm R} + N_{\rm L}}}\, \si_{\rm P}\ ,
}{elr th err comp sig}
where $\si_{\th^*}$ is the beam divergence defined in \Eq{ttm beam div} (see also the text below \Eq{sm momenta par}). The standard deviation of the $\th_x^*$ reconstruction is then
\eqref{\si^2(\th_x^*) = \si_{\rm B}^2 + \si^2_{\rm R}\ .}{elr th err proj sig}

The error estimate for the (full) scattering angle $\th^*$ measurement can be obtained by error propagation ($\th_x^*$ and $\th_y^*$ are independent variables)
\eqref{\si^2(\th^*) \equiv \si^2(\sqrt{\th_x^{*2} + \th_y^{*2}}) = {\th_x^{*2}\over \th^{*2}} \si^2(\De\th_x^*) + {\th_y^{*2}\over \th^{*2}} \si^2(\De\th_y^*)\ .}{elr th err sig}
If the beam-smearing error contribution dominates the one from finite resolution, that is $\si_{\rm B} \gg \si_{\rm R}$, then we find $\si(\th^*) = \si(\th_x^*) = \si(\th_y^*) = \si_{\rm B}$.

The error propagation can also be used to calculate the standard deviations of the momentum-transfer components (see \Eq{ttm t x y})
\eqref{{\si(t_x)\over |t_x|} = {2p\over \sqrt{|t_x|}}\, \si(\th_x^*)\ .}{elr tx err sig}
A similar result can be obtained for the (full) momentum-transfer $t$ (averaged over all values of the azimuthal angle $\ph$)
\eqref{{\si(t)\over |t|} = {2p\over \sqrt{|t|}}\,\sqrt{\si^2(\th_x^*) + \si^2(\th_y^*)\over 2}\ .}{elr t err sig}

We will test these error estimates with \abb{MC} simulations in the following two sections.


\def\OutlineLabel{High-beta* optics}
\def\TOCLabel{High-$\be^*$ optics}
\subsection[elr 1535]{High-$\BiggerFonts\mathbf\be^*$ optics}

In this section we will present the performance of the elastic reconstruction module for the case of the nominal $\be^* = 1535\un{m}$ optics (see \Sc{rp measurement}) at the center-of-mass energy $\sqrt s = 14\un{TeV}$. For that reason we have made a \abb{MC} simulation of elastic events with Elegent generator (see \Sc{elegent}) and run the entire reconstruction chain (see \Fg{sr sw structure}) up to the elastic reconstruction module. The elastic reconstruction has been performed with no cuts -- with formally infinite road-size and tolerance parameters. In this way, one may determine the optimal values of the cut parameters.

\Fg{elr 1535 ndf} shows that the most frequent numbers of degrees of freedom of the fit \Eq{elr fit} are 2 and 4. The former corresponds to the situation with 2 vertical pots hit on both sides. The latter occurs when a track hits also 2 horizontal pots on a side.

\Fg{elr 1535 rs} illustrates that it is safe to set the \pmt{road size} parameter to about $2\un{\mu rad}$ for both projections.

\bmfig
\fig{fig/pdf/elr_1535_ndf.pdf}{elr 1535 ndf}{[7cm]Histogram of the numbers of degrees of freedom in fit \Eq{elr fit} for $x$ and $y$ (the two histograms are indistinguishable).}
\fig{fig/pdf/elr_1535_rs.pdf}{elr 1535 rs}{[7cm]Histogram of the road sizes.}
\emfig

The angular resolutions are nearly the same for $x$ and $y$ projections, as shown in \Fg{elr 1535 dth}. The dominant error contribution is the beam smearing with $\si_{\th^*} = 0.3\un{\mu rad}$, which gives rise to $\si_{\rm B} = 0.21 \un{\mu rad}$ for the 2+2 configuration (i.e.~two pots active in both arms) or $\si_{\rm B} = 0.22\un{\mu rad}$ for the 2+4 configuration.

As a consequence of the low magnification values $v$ (of the order of $10^{-2}$), the vertex resolution is rather bad, see \Fg{elr 1535 dvtx}.

\bmfig
\fig{fig/pdf/elr_1535_dth.pdf}{elr 1535 dth}{[7cm]The angular reconstruction error.}
\fig{fig/pdf/elr_1535_dvtx.pdf}{elr 1535 dvtx}{[7cm]The reconstruction error of the vertex position.}
\emfig

\Fg{elr 1535 res t} shows the relative $t$-resolution with a fit of the form of \Eq{elr t err sig}. The fit describes the data well, the analytic estimate for the numerator is $3.08\un{GeV}$ (for the 2+2 configuration) and $3.18\un{GeV}$ (for the 4+2 configuration), which agrees well with the fit result.

\fig{fig/pdf/elr_1535_res_t.pdf}{elr 1535 res t}{[7cm]The $t$-resolution.}


\def\OutlineLabel{Medium-beta* optics}
\def\TOCLabel{Medium-$\be^*$ optics}
\subsection[elr 90]{Medium-$\BiggerFonts\mathbf\be^*$ optics}

In this section, we will show the elastic-reconstruction performance for the nominal $\be^* = 90\un{m}$ optics (see \Sc{rp measurement}) at $\sqrt s = 14\un{TeV}$. Like in the previous section, we have used no cuts, in order to find optimal values of the cut parameters.

For this optics, the hits are concentrated around $x=0\un{mm}$ (the effective length $L_x$ is very small, see \Fg{ttm hit distribution}). This means that the horizontal \abb{RP}s can not contribute to the measurement of elastic scattering. Therefore we expect most frequent hit-configuration to be 2 vertical pots on both sides. That means 2 degrees of freedom for the fit \Eq{elr fit}, which is confirmed by \Fg{elr 90 ndf}.

Since the effective length $L_x$ is too small, the road-search algorithm is not efficient for the $x$ projection (the road sizes are excessively large). For the $y$ projection a road-size value of about $12$ is safe, see \Fg{elr 90 rs}.

\bmfig
\fig{fig/pdf/elr_90_ndf.pdf}{elr 90 ndf}{[7cm]A histogram of the number of degrees of freedom in fit \Eq{elr fit} (the two histograms are overlapping).}
\fig{fig/pdf/elr_90_rs.pdf}{elr 90 rs}{[7cm]A histogram of the road sizes.}
\emfig

The $\th_y$ angular resolution is dominated by the beam divergence which corresponds to $\si_{\rm B} = 1.7\un{\mu rad}$. For the $x$ projection it is deteriorated by the low $L_x$ values.

The values of magnification $v$ are too small (of the order of $-2$ for the horizontal and $10^{-2}$ for the vertical projection) for a reasonable vertex resolution, see \Fg{elr 90 dvtx} (the curve for the $y$ projection is not even drawn).

\bmfig
\fig{fig/pdf/elr_90_dth.pdf}{elr 90 dth}{[7cm]The angular reconstruction error.}
\fig{fig/pdf/elr_90_dvtx.pdf}{elr 90 dvtx}{[7cm]The reconstruction error of the vertex position.}
\emfig

The analytical estimate \Eq{elr t err sig} for the $t$-resolution, drawn in \Fg{elr 90 res t}, gives $4.0\un{GeV}/\sqrt{|t|}$. This differs slightly from the fit value. For this optics, the nominal distance between the top and bottom RP detector edges is not negligible anymore (see \Fg{ttm hit distribution}). Therefore the averaging over all azimuthal angles $\ph$ becomes a too crude approximation. It gives too much weight to the $t_x$ component, which is burdened by a much larger error. That is why the analytical approach overestimates the error.

\fig{fig/pdf/elr_90_res_t.pdf}{elr 90 res t}{[7cm]The $t$-resolution.}


\iffalse
\section[dqm]{Data quality monitor}

The data quality monitor (Totem\abb{DQM}) is an interactive program that can visualize all steps of data processing. It has been designed for data quality control during data acquisition, but it has also proved very useful for visual event scanning (inspection of events' details such as hit topologies) and for software tuning and debugging.

\fig[\the\hsize]{fig/external/dqm.png}{dqm ex}{A screen shot of several Totem\abb{DQM} windows.}

The Totem\abb{DQM} \bref{totemdqm} provides a multi-window/tab user interface, each of the windows contains a configurable grid of plots, see an example in \Fg{dqm ex}. The plots can be either \em{cumulative} (built from the entire event sample) of \em{event-related} (showing details of a chosen event). Cumulative plots are for example $U$ and $V$ hit profiles (bottom-right window in \Fg{dqm ex}) or $xy$ hit maps (top-right window). Several event-related plots are shown in the background window (left-hand side): track fits in $U$ and $V$ projections and a $3D$ view of the fitted track within the detector package.

The Totem\abb{DQM} is fully integrated in the \abb{TOTEM} offline software. Its predecessor (Monitor \bref{monitor}) is a simpler and standalone program of similar kind. It was and still is used for low (\abb{VFAT}) level tests such as \abb{RP} sensor production tests or system calibrations before data-taking.
\fi
