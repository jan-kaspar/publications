\chapter{RP simulation and reconstruction methods}

In \Sc{rp measurement} we have described how scattered protons can be detected by the RP detectors. This processes can be simulated by computer programs which is essential for development and tuning of reconstruction techniques. That for processes where the scattered proton kinematics is deduced from the RP hits. The structure of the simulation and reconstruction software is sketched in \Fg{sr sw structure}. Beyond the aforemetined \em{simulation} and \em{reconstruction} blocks, you can see three more: \em{alignment} (special reconstruction focused to the alignment of RP detectors), \em{raw-data} (experimental data preprocessing) and \em{trigger} (trigger related analyses).

\fig{fig/pdf/sr_sw_structure.pdf}{sr sw structure}{The structure of the RP simulation and reconstruction software.}

Our contribution to the software mostly complements the work described in \bref{hubert}. Below we will briefly describe all the essential components and later will give details for our modules.

\em{Event generator}.
The simulation process starts with generation of particles at the interaction point. This can be either a \em{particle gun} or a \em{physics event generator}. Particle guns generate particles according to some given distributions and are useful for specialized tests. Physics event generators simulate physics processes such as elastic scattering, single diffraction etc. We use common generators like Pythia \bref{pyhia6,pythia8} or Phojet \bref{phojet} and a custom developed Elegent (see \Sc{elegent}).

\em{Smearing}.
Most Monte Carlo generators simulate head-to-head collisions of particles of a fixed energy at a given point. However, in reality there are two bunches collided under a certain crossing angle. Within a bunch, particles do not have identical energy (energy smearing) and they are not all collinear (angular smearing). The bunches have non-zero dimensions and therefore the collision may take place at various points (vertex smearing). This module introduces these smearing effects in order to obtain realistic simulations. It will be discussed in detail in \Sc{beam smearing}

\em{Geant4 and proton transport}.
This module performs two actions: simulates energy depositions in sensitive volumes and propagates protons in between. The sensitive volumes are located around the IP5 (CMS, T1 and T2) and at the RP stations at $\pm 147\un{m}$ and $\pm 220\un{m}$. Both actions are implemented within the Geant4 \bref{geant4} simulation kit. The proton transport uses a polynomial parameterization model described in Chap.~6 of \bref{hubert}. For details on the implementation see Sec.~7.3 in \bref{hubert}.

\em{Detector response and electronics simulation}. The energy deposited in the silicon detectors gives raise to electron-hole pairs, which are collected by the strips and then processed by the VFAT2 chips \bref{vfat}. Details can be found in Sec.~7.4 in \bref{hubert}.

\em{DIGI}.
Since the VFAT chips are digital, their output is a boolean value per silicon sensor channel. We call these data DIGI. This is the meeting point of the simulation and raw-data chains and is the start point for reconstructions and analyses.

\em{Raw data}.
Raw data are those saved by the DAQ system.

\em{Raw-data validation}.
The form of raw data is given by the DAQ and can change during time according to needs. Hence before the data is used, they must be converted to a common format -- DIGI in our case. The DAQ system has only a limited possibility to run error checks online, therefore most of then must of run offline. This is the main duty of this module.
\TODO{Standalone section?}

\em{Fast simulation}
\Sc{fast simu}


\em{Clusterization}
is the first step of the reconstruction chain. Due to charge-sharing effects, it is possible that one track fires two or more neighbouring strips. Such strip clusters need be found and later treated as a single hit.

\em{RECO}.
The position of a cluster can be turned into the distance (in the read-out direction) from the center of the sensor. We call such data RECO.


\em{Pattern recognition}.
In this step we would like to find RECO hits belonging to (a) track(s) and suppress those which are result of noise of errors. For that we may use the fact that we have five planes in every projection and that particle tracks are straight lines. Hence hits forming line patterns are likely to come from a particle track, isolated hits are likely to be noise. Such an algorithm will be discussed in \Sc{pattern reco}. An alternative to this method -- road search algorithm -- is presented in Sec.~8.1.4 in \bref{hubert}. It is based on an additional piece of knowledge that physics protons are always very parallel to the beam. However, a possibility to reconstruct tracks with high angles will turn out important for alignment applications (see \Fg{al eig theta}). \TODO{problem with multiple tracks}

\em{One-RP track fitting}.
In this step, hits from $U$ and $V$ projections are combined into one XYZ fit, see Sec.~8.1.5 in \bref{hubert}.

\em{Station track fitting} is similar to one-RP track fit, but here all hits from an entire (or a part) station are combined. This module has been developed mainly for alignment purposes. In order to select really clean tracks, it also comprises outlier removal procedure. It will be discussed in \Sc{al data sel}.

\em{Physics reconstruction}.
In this step, the one-RP track fits are used to reconstruct proton kinematics at IP5. There are two versions -- \em{general} suitable for any diffractive protons and \em{elastic} which is a lighter version for elastic events. The latter one will be discussed in \Sc{el reco}.

\em{Alignment} modules perform a special analyses focused on the alignment of RP sensors wrt.~each other and wrt.~the beam. The entire Chapter~\sref{al} will be devoted to RP alignment. \TODO{Standalone section with implementation details??}

Various \em{coincidence-chip and trigger analyses} have been performed to validate the performance of the trigger system.

\section[elegent]{Elegent}

Elegent is acronym for ELastic Event GENeraTor. It generates elastic $\rm pp$ and $\rm\bar pp$ collisions with $\d\si/\d t$ distributions according to the four phenomenological models discussed in \Sc{el models}.

It uses the inversion method (see \bref{wikipedia} key ''Inverse transform sampling''). This means one has to prepare cumulative distribution functions (cdfs.) first. The Elegent package contains a standalone program to do so. For a chosen energy and interaction type ($\rm pp$ or $\rm\bar pp$), the program calculates (samples in a given range) cdfs.~for every models and saves them as a ROOT file. In fact, for each hadronic model, there are three cdfs.~with various levels of Coulomb interaction inclusion: pure hadron (Coulomb effects are completely neglected), West-Yennie (\Eq{el WY}) and Kundr\' at-Lokaj\' i\v cek (\Eq{el KL}).

The generation program itself loads a selected cdf., can reduce the available $t$-region and inverts the cdf. The generated events are saved in the standard HepMC format. Technical details and usage hints can be found in \bref{elegent}.


\section[beam smearing]{Beam smearing}

The aim of this module is to include beam smearing effects that are usually not considered by event generators. As it has been mentioned above, the beam smearing comprises three components: \em{angular smearing} (the particles in a bunch are not all parallel), \em{energy smearing} (there is energy fluctuation within a bunch) and \em{vertex smearing} (the bunches have non-zero dimensions, hence the interactions can take place in various space points).

This section is an updated version the internal note \bref{smearing}.


\subsection{Angular and energy smearing}

Let's discuss angular and energy smearing first. A collision in LAB frame (a frame bound to the accelerator). On the other hand, MC generators use a different frame to describe events -- a frame where incident particles have same momenta and opposite directions parallel to $z$ axis. This frame will be referred as the MC frame. Obviously, we want to find a transformation between these two frames. It will be done in two steps. 

First, we find the Lorentz boost which makes incident particles have equal momenta and opposite directions. If we write the transformation of a four-momentum $(E|\vec p)$ to $(E'|\vec p')$ in the following form
\eqref{\eqalign{
E'      &= \ga\,(E - \vec p\cdot\vec\be)\cr
\vec p' &= \vec p  +  (\ga - 1) {\vec p \cdot \vec \be\over \be^2}\vec\be - \ga E \vec\be\cr
}\qquad\eqalign{
\be &= |\vec\be|\cr
\ga &= {1\over\sqrt{1 - \be^2}}\cr}
\ ,}{sm lorentz}
one can find that the $\vec\be$ needed for our purpose is
\eqref{\vec\be = {\vec p_1 + \vec p_2\over E_1 + E_2}\ ,}{sm beta}
where $\vec p_1, \vec p_2$ are the momenta and $E_1, E_2$ are the energies of the incident particles in the LAB frame. Let's denote this transformation $L(\vec\be)$ and the boosted momenta of the incident particles $\vec p_1'$ and $\vec p_2'$.

In the second step, we rotate the vectors $\vec p_1'$ and $\vec p_2'$ to be parallel to the MC frame $z$ axis. We use Rodrigues' formula to describe the rotation of a vector $\vec v$ around a unit vector (axis) $\vec a$:
\eqref{R(a, \om)\, \vec v = \vec v\,\cos\om + \vec a\times\vec v\,\sin\om + \vec a\cdot\vec v\,\vec a\,(1 - \cos\om)\ .}{sm rotation}
For our purpose, one may identify\footnote{In fact, this is just one of the possible solutions, rotation around $\vec a$ axis is arbitrary.}
\eqref{\vec a = {\vec p_1' \times \hat z\over |\vec p_1' \times \hat z|}, \qquad \cos\om = {\vec p_1' \cdot \hat z\over |\vec p_1'|}}{sm axis angle}
where $\hat z$ is the unit vector in the $z$ direction in the frame after the boost. Obviously, the coordinate representation is $\hat z = (0, 0, 1)$.

Unfortunately, this is not the full story. MC generators usually produce events for a fixed center-of-mass energy $\sqrt{s}$. However, in the real case, $\sqrt{s}$ varies slightly due to the smearing effects. Since the variation is small it might be neglected. But for consistency reason, one had better make sure that the scattering products sum up to the same $\sqrt{s}$ as for which the event has been produced. There is generally no correct way how to accomplish that. Nevertheless, as the variations are small, it does not matter much. Therefore, let's scale the energy of the outgoing particles
\eqref{E_i^{\rm MC} \rightarrow \chi\, E_i^{\rm MC},\qquad \chi = \sqrt{s_{\rm LAB}\over s_{\rm MC}}\ .}{sm energy scaling}
The momenta of the particles are scaled such that their masses are preserved.

To summarize, if $(E|\vec p)_{\rm MC}$ is the four-momentum for a particle produced in a MC event, then the LAB four-momentum can be written
\eqref{(E|\vec p)_{LAB} = L(-\vec\be)\,R(\vec a, -\om)\, S(\chi)\, (E|\vec p)_{MC}\ ,}{sm mc to lab}
where $S(\chi)$ stands for the energy scaling procedure.


\fig[8cm]{fig/pdf/smearing_angular_energy.pdf}{smearing angular energy}{Sketch of angular and energy smearing in XZ plane.}

The above formula provides a method to apply angular and energy smearing to MC particles. The missing step to have a smearing MC generator is to know the distributions of the quantities $\vec\be$, $\vec a$, $\om$ and $\ch$. But these can be calculated from beam smearing parameters as discussed in \Sc{pr transport}. Assuming the crossing angle $\al$, see \Fg{smearing angular energy}, one can parameterize the momenta of the incident particles as
\eqref{\vec p_i = \pm p_{\rm nom}\,(1 + \xi_i)\,\pmatrix{\cos\al & 0 & \mp \sin\al\cr 0 & 1 & 0 \cr \pm\sin\al & 0 & \cos\al\cr}\,\pmatrix{C_i\cr S_i\cr \sqrt{1 - C_i^2 - S_i^2}}\ ,}{sm momenta par}
where $i\in {1, 2}$ and the upper/bottom sign corresponds to particle 1/2. $C_i$ and $S_i$ describe the angular smearing in X and Y and according to \Eq{to beam div} one assign them distributions $N(0, \si_\th^2)$. In fact, the tails of the normal distribution must be cut off since the parameterization requires $S_{1,2}^2 + C_{1,2}^2 \leq 1$. But as any realistic $\si_\th \ll 1$, the effect is negligible. The $\xi$ parameter accounts for the energy smearing, the expected distribution is $N(\bar\xi, \si_\xi^2)$ (see \Eq{to energy fl}).

The smearing effects and the crossing angle are rather small: $\si_\th \sim \O{10^{-6}}$, $\al \sim \O{10^{-4}}$ and $\si_\xi \sim \O{10^{-4}}$ (see \Sc{pr transport}). Therefore, one may simplify \Eq{sm mc to lab} by keeping just the first oder terms. It will yield an easily iterpretable forumula which will become useful reconstruction uncertainty estimates. Also, bearing in mind the LHC energies, we will approximate $E\approx p$ for all the particles involved.

In this approximation \Eq{sm beta} gives
\eqref{\vec\be \simeq {1\over 2}\pmatrix{-2\al + C_1 - C_2\cr S_1 - S_2\cr \xi_1 - \xi_2}}{sm beta expl}
and thus $\ga\simeq 1$ (all other terms are of second and higher orders). Then, the Lorentz boost \Eq{sm lorentz} and rotation \Eq{sm rotation} simplify to
\eqref{\vec p' \simeq \vec p - |\vec p| \vec\be,\qquad E' \simeq E - \vec p\cdot\vec\be\ ,}{sm lorentz expl}
\eqref{R(\vec a, \om)\,\vec v \simeq \vec v + {1\over 2}\pmatrix{S_1 + S_2\cr -C_1 - C_2\cr 0} \times \vec v\ .}{sm rotation expl}
The energy scaling factor turns out
\eqref{\ch \simeq 1 + {\xi_1 + \xi_2\over 2}\ .}{sm energy scaling expl}

Now we are ready to apply \Eq{sm mc to lab} to an outgoing (MC generated) particle with momentum $\vec p_{\rm MC}$. Let's limit ourselves to particles that can reach Roman Pot stations, that means particles scattered to small angles $\th \leq 10^{-3}$. A convenient parameterization, thus, is
\eqref{\vec p_{\rm MC} = \pm p\,\pmatrix{\th\cos\ph\cr \th\sin\ph\cr 1\cr} \.}{sm diff mc}
The particles with $+$ sign can be detected in the right arm stations, with $-$ sign in the left arm. Still working in the leading approximation, one finds
\eqref{\vec p_{\rm LAB} = \pm p\,\pmatrix{\th\cos\ph + \De\th_x\cr \th\sin\ph + \De\th_y\cr 1 + \xi\cr},
\quad \xi = \left\{\matrix{\xi_1\cr\cr \xi_2}\right.,
\quad \De\th_x = \left\{\matrix{C_1 - \al\cr\cr C_2 + \al\cr}\right.,
\quad \De\th_y = \left\{\matrix{S_1\qquad\hbox{for right arm}\cr\cr S_2\qquad\hbox{ for left arm}\cr}\right.\ .}{sm diff lab} %}}}

The interpretation is quite intuitive. Let us take, for instance, a forward proton targeting the right arm and let us focus on the X projection. Its full scattering angle is a sum of three components: the original (MC) scattering angle ($\th\cos\ph$), crossing angle ($-\al$) and the X component of the beam divergence ($C_1$). The proton inherits the energy shift $\xi_1$ from the first incident proton.

\iffalse
Using the statistical properties suggested in the previous section yields the following relation between variances (recalling $\si_\th$ refers to the beam divergence)
\eqref{\si_{\De\th_x} = \si_{\De\th_y} = \si_{C_1} = \si_{C_2} = \si_{S_1} = \si_{S_2} = \cases{
{\si_\th\over\sqrt2}\qquad\hbox{for parameterization \Eq{mom par 1}}\cr
\si_\th\qquad\hbox{for parameterization \Eq{mom par 2}}\cr
}\ .}{delta th sigma}
\fi


\subsection{Vertex smearing}

\fig[8cm]{fig/pdf/smearing_vertex.pdf}{smearing vertex}{Bunch collision with crossing angle $\al$.}

\Eq{in luminosity}, one of the luminosity definitions, suggests that function
\eqref{h(x, y, z; t) = {1\over {\cal L}_{int}}\,j(x, y, z; t)\ \rh_T(x, y, z; t)}{sm pdf}
can be interpreted as the probability density function of finding an interaction (vertex) at position $(x, y, z)$ and time $t$. Recalling that $j$ stands for the flux of bombarding particles and $\rh_T$ is the density of target particles. This formula can well be adatped for a collision of two bunches, as depicted in \Fg{smearing vertex}. The two bunches, each propagating (in the LAB frame) with speed $v$, are collided under a crossing angle $\al$. The flux $j$ in \Eq{sm pdf} can be expressed as $v_{\rm rel}\,\rh$, where $v_{\rm rel} = 2v\cos\al$ is the relative velocity of the two bunches and $\rh$ is the density of one of them. Therefore one can write
\eqref{h(x, y, z; t) = {2v\cos\al\over {\cal L}_{int}}\ \rh_1(x, y, z; t)\, \rh_2(x, y, z; t)\.}{sm pdf2}
The $\rh_{1,2}$ densities correspond to the two bunches (note that the formula is symmetric against swap of the two bunches, as it should be).

If $\rh_0(\tilde x, \tilde y, \tilde z)$ is a (time-independent) particle density in the rest frame of bunch 2 (the tilded frame in \Fg{smearing vertex}), then the (time-dependent) particle density $\rh_2(x, y, z)$ in the LAB frame (the non-tilded one) can be obtained by means of coordinate transformation (we assume that the origins of the tilded and the non-tilded frame coincide in $t=t'=0$)
\eqref{\eqnarray{
\tilde x &= x\cos\al\ - z\sin\al \cr
\tilde y &= y\cr
\tilde z &= \ga \left( z\cos\al\ + x\sin\al + vt \right),\qquad \ga = {1\over\sqrt{1 - v^2}}\ .\cr
}}{sm coord trans}
The result reads
\eqref{\rh_2(x, y, z; t) = \ga\, \rh_0\Big(x\cos\al - z\sin\al, y, \ga(z\cos\al + x\sin\al + vt) \Big)\ .}{sm density2}
The overall factor $\ga$ is needed to preserve normalization:
\eqref{\int \rh_0(\tilde x, \tilde y, \tilde z)\ \d\tilde x\d\tilde y\d\tilde z = \int \rh_2(x, y, z)\ \d x\d y\d z\ .}{sm rho normalization}
The density for bunch 1 can be obtained analogically
\eqref{\rh_1(x, y, z; t) = \ga\, \rh_0\Big(x\cos\al + z\sin\al, y, \ga(z\cos\al - x\sin\al - vt) \Big)\ .}{sm density1}

The Lorentz contracted particle density of each bunch can be well approximated by a Gaussian \TODO{reference}
\eqref{\ga \rh_0(x, y, \ga z) = {n_B\over (2\pi)^{3/2}\si_x\si_y\si_z}\,\exp\left(-{ x^2\over 2\si_x^2}-{ y^2\over 2\si_y^2}-{ z^2\over 2\si_z^2}\right),}{sm density}
where $n_B$ is the number of protons in a bunch and the variances $\si_x, \si_y$ and $\si_z$ refer to the bunch dimensions in the LAB frame.

Inserting \Eq{sm density1,sm density2,sm density} to \Eq{sm pdf2} yields
\eqref{h(x, y, z; t) \propto \exp\left[- {\cos^2\al\over\si^2_x} x^2 - {y^2\over\si^2_y} - \left({\sin^2\al\over\si^2_x} + {\cos^2\al\over\si^2_z}\right)z^2 - {(vt + x\sin\al)^2\over\si^2_z}\right]\.}{sm vertex full distribution}
This means that the random variables $x$ and $t$ are not independent. But as we are not interested in the time of collision, we can integrate over the time $t$ and obtain the \hbox{p.d.f.} only for the spatial coordinates of the vertex
\eqref{h(x, y, z) \propto \exp\left[- {\cos^2\al\over\si^2_x} x^2 - {y^2\over\si^2_y} - \left({\sin^2\al\over\si^2_x} + {\cos^2\al\over\si^2_z}\right)z^2\right]\.}{sm vertex distribution}
We can see that the vertex distribution retains a Gaussian form. The mean values of $x, y$ and $z$ are zero while the effective variations are
\eqref{\si_{x,\rm ef\!f} = {\si_x\over\sqrt{2}\cos\al},\quad \si_{y,\rm ef\!f} = {\si_y\over\sqrt{2}},\quad \si_{z,\rm ef\!f} = {\si_z\over\sqrt{2}}\,{\si_x\over\sqrt{\si_z^2\sin^2\al + \si_x^2\cos^2\al}} \.}{sm effective variations}

\section[fast simu]{Fast simulation}

In order to verify the functionality of our track-based alignment (see Chapter~\sref{al}) we had perform a number of MC simulations. With full Geant4 simulation it would have had taken an enormous time. Instead we developped a fast simulation modules. As indicated in \Fg{sr sw structure}, there are two versions: \em{Fast full simulation} and \em{fast station simulation}. The first one takes as input smeared particles at IP5 and transport them to the RP station with the polynomial optics approximation (the one used later for reconstruction). The latter version generates random tracks at the beginning of a chosen station. Subsequent processing is in common for both versions. Within a station, the tracks are interpolated linearly and intersections with all sensors are calculated. If \pmt{roundToPitch} is set to True, then the hit point is rounded to the nearest strip or inter-strip position. The mechanism is illsutrated in \Fg{sr fast simulation scheme}. If the intersection falls in the blue region, the creation of a double-strip cluster is assumed and the hit position is rounded to the inter-strip position (dash-dotted line). Otherwise one-strip clusters are assumed and the position is rounded to the nearest strip. The strip pitch can be set by \pmt{pitch} parameter, the size of the double-strip-cluster region (blue) by \pmt{dscrWidth} parameter. All hits are assigned errors of pitch$/\sqrt{12}$ unless \pmt{dscReduceUncertainty} = True. In that case, the error of double-strip cluster hits reduced to half.

\fig{fig/pdf/sr_fast_simulation_scheme.pdf}{sr fast simulation scheme}{One and two-strip cluster regions as used in the fast simulation. The solid lines represent the strip centers, the dash-dotted lines mark the half way between the strips. The blue areas correspond to the double-strip-cluster regions, the white ones to the regions where one-strip clusters are created.}


\section[pattern reco]{Pattern recognition}

The input to this module is a list of RECO hits among which we would like to find those lying around particle tracks. This search is performed pot per pot, where any physics track is a straight line. Thus our task is to find straight line patterns within the data. The fact, that there are just two read-out directions (U and V) makes it special. In a way simpler -- one 2-dimensional task can be split into two 1-dimensional ones (one per projection). In a way more complicated -- if there are several tracks in a RP, we may find line patterns it both projections, but there is now clue how to combine them togher.
%For example, imagine two tracks in a pot. We would find two patterns in both projections, yielding four possible combinations. However, two of them are real and two are fake (ghosts).
Even if we applied rotational alignment corrections, the deviations from the U and V read-out directions would be insufficient to perform a 2D pattern search. 

Our algorithm is an optimization of the Hough transform pattern search (see e.g. \bref{wikipedia} key ''hough transform''). Let us parameterize the line patterns in the following way ($q$ stands for either $u$ or $v$)
\eqref{q = a (z - z_0) + b\ .}{pr line par}
$z_0$ refers to the center of the RP (this is the ''nearest'' place to all the planes, therefore it minimizes the extrapolation error in $b$ determination). The Hough transform assignes to each point $(z, q)$ a line in $ab$ space:
\eqref{(z, q) \rightarrow b = - (z - z_0) a + q \ .}{pr transform}
This process is shown in \Fg{sr pattern reco}: each of the points in the left plot is transformed to a line (of the same color) in the right plot. The effect is evident. The intersections of colorful lines (corresponding to the colorful points that lie around a line) cumulate together, but the intersections of the black line (representing a noise hit) are scattered around. Hence the taks of finding line patters is reduced to a (intersection) cluster search.

Since the RECO hit positions are multiples of pith $P$, it is natural to measure $b$ in units of $P$. Similarly, we will give slopes $a$ in multiples of $a_0 \equiv P / d$, where $d = 9 \un{mm}$ is the nominal distance between adjacent planes of the same strip orientation.

\fig{fig/pdf/sr_pattern_reco.pdf}{sr pattern reco}{Illustration of the pattern recognition method. Left: sideview on the five sensors (black vertical lines) of identical strip orientation (U or V). The small horizontal ticks represent the strip positions. The thick inclined line shows a track, the colorful points around mark the measurments by the five sensors. The black dot in the upper-left corener represents an error, due to noise for instance. Right: the corresponding Hough diagram. The colors of the lines correspond to the colors of the points in the left plot. The line intersections are marked with black dots. The gray region represents a cluster (of the optimal size -- see \Tb{pattern reco par}).}

Now, let us describe the cluster-search algorithm. Every RECO hit is assigned a weight $w = \si_0/\si$, where $\si_0 = 66/\sqrt{12} \un{\mu m}$ is the uncertainty of a 1-strip cluster. The weight of a line crossing is given by the sum of the two contributing hit weights. The algorithm can be described as follows.

\bitm
\itm Build clusters. Go throught all crossings, try to match each crossing to any of the already existing clusters. A crossing falls into a cluster if
\eqref{|a - a_c| < \pmt{clusterSize\_a}/2 \quad \hbox{ and }\quad |b - b_c| < \pmt{clusterSize\_b}/2\ ,}{pr cluster match}
where $a$ and $b$ are the coordintates of the crossing and $a_c$ and $b_c$ give the position of the cluster. The position is calculated as a weighed mean over all contributing crossings: $a_c = \sum a_i w_i / \sum w_i$.
If match, add the crossing to the cluster. If no match, create a new cluster containing the crossing only.
\itm Calculate cluster weights as the sum of its hit weights.
\itm Take the cluster with the highest weight. If its weight is lower than \pmt{threshold}, stop. If not, the cluster corresponds to a recognized track. Remove its points from the list and return to the step 1) to recognize more line patterns.
\eitm

The \pmt{threshold} parameter gives an effective minimal number of hits for a cluster to be trusted as a reasonable line. The other two critical parameters are the cluster sizes. If set too low, real tracks would not be recognized, if set too high, noise hits may get selected or even multiple tracks may be merged. The needed cluster size depends on the expected deviations of the individual measurements from the track. These deviations have two major ingredients: pitch rounding and misalignments. To find the optimal cluster sizes we made a simple MC test and a real data analysis, see \Fg{sr pattern reco tune}. For the MC test, we simulated  1000 (internal) misalignment scenarios compatible with \Fg{al comp det per unit} (slope $50\un{\mu m}$ per detector, deviations with the variation of $20\un{\mu m}$). For each misalignment, we simulated 1000 tracks through 5 planes at nominal distances $d$, the angular spread of tracks was $\si_\th = 5\un{mrad}$. For each track we calculated the cluster sizes and filled the values in the blue histograms. The red curves correspond to an analysis of run 3728, file 1. For both projection we required five planes with just one hit -- a perfect track. There are non-negligible differences between the two histograms at lower cluster sizes, but both agree that there is practically nothing above $3a_0$ and $4P$.

\fig{fig/pdf/sr_pattern_reco_tune.pdf}{sr pattern reco tune}{Cluster-size distributions: MC simulation (blue) and run 3728 (red).}

To optimize the performance, we apply the cuts below before performing the search.
\bitm
\itm Planes with more than \pmt{maxHitsPerPlaneToSearch} hits per plane are tagged as unusuable. We recall that only events with one track can be fully reconstructed.
\itm Events with less reasonable (i.e.~non-empty and not unusable) planes per projection than\break \pmt{minPlanesPerProjectionToSearch} are skipped.
\eitm

\Tb{pattern reco par} summarizes the parameters of the algorithm and gives their default/optimal values. \Fg{sr pattern reco ex} provides an example of the recognition results.

\tab[\strut\quad\pmt{#}\hfil&\quad\hfil$#$\hfil\quad\cr]{pattern reco par}{The parameters of the pattern recognition algorithm with their default values.}{\ln
clusterSize\_a& 3a_0\cr
clusterSize\_b& 4P\cr
maxHitsPerPlaneToSearch& 4\cr
minPlanesPerProjectionToSearch& 3\cr
threshold& 2.99\cr\ln
}


\fig{fig/pdf/sr_pattern_reco_ex.pdf}{sr pattern reco ex}{An example of the patter recognition. Run 3230, file 0, event 111, unit 45-220-near. Left: a track plus noise in the bottom pot (V sensors). Right: many tracks in the horizontal pot (U sensors). The red lines correspond to the recognized patterns (cluster centers).}

\section[el reco]{Reconstruction of elastic events}

\input elasticReco.tex
